{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"music-transformer-train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"colab_type":"code","executionInfo":{"elapsed":19211,"status":"ok","timestamp":1559096165648,"user":{"displayName":"양기창","photoUrl":"https://lh3.googleusercontent.com/-4HfYuDxbUNQ/AAAAAAAAAAI/AAAAAAAAAD8/1C9xKnO2Ji8/s64/photo.jpg","userId":"09400683122953982681"},"user_tz":-540},"id":"vT_Gdqetn8XT","outputId":"1dd6111f-dc01-479e-a423-cd38f74cc147"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","executionInfo":{"elapsed":1296,"status":"ok","timestamp":1580643786159,"user":{"displayName":"Melvin Li","photoUrl":"","userId":"16223749517006263645"},"user_tz":-480},"id":"IiDyGS9DoUme","outputId":"31d239fa-57fa-4c5d-87c5-5c0e303075cf"},"outputs":[],"source":["cd /content/drive/'My Drive'/MusicTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"colab_type":"code","executionInfo":{"elapsed":4417,"status":"ok","timestamp":1580643792800,"user":{"displayName":"Melvin Li","photoUrl":"","userId":"16223749517006263645"},"user_tz":-480},"id":"ttZxh2SyKFj8","outputId":"cdc236f3-1e67-41af-ed16-fab5efdcb845"},"outputs":[],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":5368,"status":"ok","timestamp":1580643803687,"user":{"displayName":"Melvin Li","photoUrl":"","userId":"16223749517006263645"},"user_tz":-480},"id":"DaY3Po_wLDYC","outputId":"cb351093-bb03-48c6-fe7d-02403bc62c42"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from model import MusicTransformerDecoder\n","from custom.layers import *\n","from custom import callback\n","import params as par\n","from tensorflow.python.keras.optimizer_v2.adam import Adam\n","from data import Data\n","import utils\n","import argparse\n","import datetime\n","import sys\n","tf.executing_eagerly()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["l_r = None\n","batch_size = 2\n","pickle_dir = 'music'\n","max_seq = 2048\n","epochs = 5\n","is_reuse = False\n","load_path = None\n","save_path = \"result/02-02\"\n","multi_gpu = True\n","num_layer = 6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"S3vb_7QdngrW"},"outputs":[],"source":["dataset = Data('dataset/processed')\n","print(dataset)\n","learning_rate = callback.CustomSchedule(par.embedding_dim) if l_r is None else l_r\n","opt = Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","mt = MusicTransformerDecoder(\n","            embedding_dim=256,\n","            vocab_size=par.vocab_size,\n","            num_layer=num_layer,\n","            max_seq=max_seq,\n","            dropout=0.2,\n","            debug=False, loader_path=load_path)\n","mt.compile(optimizer=opt, loss=callback.transformer_dist_train_loss)"]},{"cell_type":"markdown","execution_count":null,"metadata":{"colab_type":"text","id":"DV-qQqe_TM3U"},"outputs":[],"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"colab_type":"code","executionInfo":{"elapsed":2658,"status":"error","timestamp":1559096593998,"user":{"displayName":"양기창","photoUrl":"https://lh3.googleusercontent.com/-4HfYuDxbUNQ/AAAAAAAAAAI/AAAAAAAAAD8/1C9xKnO2Ji8/s64/photo.jpg","userId":"09400683122953982681"},"user_tz":-540},"id":"ghmPk2DsTPv1","outputId":"29cf9a1f-6eda-42aa-e935-ed8816b3c0c8"},"outputs":[],"source":["current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","train_log_dir = 'logs/mt_decoder/'+current_time+'/train'\n","eval_log_dir = 'logs/mt_decoder/'+current_time+'/eval'\n","train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n","eval_summary_writer = tf.summary.create_file_writer(eval_log_dir)\n","\n","idx = 0\n","for e in range(epochs):\n","    mt.reset_metrics()\n","    for b in range(len(dataset.files) // batch_size):\n","        try:\n","            batch_x, batch_y = dataset.slide_seq2seq_batch(batch_size, max_seq)\n","        except:\n","            continue\n","        result_metrics = mt.train_on_batch(batch_x, batch_y)\n","        if b % 100 == 0:\n","            eval_x, eval_y = dataset.slide_seq2seq_batch(batch_size, max_seq, 'eval')\n","            eval_result_metrics, weights = mt.evaluate(eval_x, eval_y)\n","            mt.save(save_path)\n","            with train_summary_writer.as_default():\n","                if b == 0:\n","                    tf.summary.histogram(\"target_analysis\", batch_y, step=e)\n","                    tf.summary.histogram(\"source_analysis\", batch_x, step=e)\n","\n","                tf.summary.scalar('loss', result_metrics[0], step=idx)\n","                tf.summary.scalar('accuracy', result_metrics[1], step=idx)\n","\n","            with eval_summary_writer.as_default():\n","                if b == 0:\n","                    mt.sanity_check(eval_x, eval_y, step=e)\n","\n","                tf.summary.scalar('loss', eval_result_metrics[0], step=idx)\n","                tf.summary.scalar('accuracy', eval_result_metrics[1], step=idx)\n","                for i, weight in enumerate(weights):\n","                    with tf.name_scope(\"layer_%d\" % i):\n","                        with tf.name_scope(\"w\"):\n","                            utils.attention_image_summary(weight, step=idx)\n","                # for i, weight in enumerate(weights):\n","                #     with tf.name_scope(\"layer_%d\" % i):\n","                #         with tf.name_scope(\"_w0\"):\n","                #             utils.attention_image_summary(weight[0])\n","                #         with tf.name_scope(\"_w1\"):\n","                #             utils.attention_image_summary(weight[1])\n","            idx += 1\n","            print('\\n====================================================')\n","            print('Epoch/Batch: {}/{}'.format(e, b))\n","            print('Train >>>> Loss: {:6.6}, Accuracy: {}'.format(result_metrics[0], result_metrics[1]))\n","            print('Eval >>>> Loss: {:6.6}, Accuracy: {}'.format(eval_result_metrics[0], eval_result_metrics[1]))\n","              \n","            "]}]}