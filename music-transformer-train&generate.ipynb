{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"music-transformer-train&generate.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"vT_Gdqetn8XT","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IiDyGS9DoUme","colab":{}},"source":["cd /content/drive/'My Drive'/MusicTransformer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ttZxh2SyKFj8","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DaY3Po_wLDYC","colab":{}},"source":["!pip install -r requirements.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N7VCuTpdnJHs","colab":{}},"source":["!pip list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JSfDnqXRnJHu","colab":{}},"source":["from model import MusicTransformer, MusicTransformerDecoder\n","from custom.layers import *\n","from custom import callback\n","import params as par\n","from tensorflow.python.keras.optimizer_v2.adam import Adam\n","from data import Data\n","import utils\n","import argparse\n","import datetime\n","import sys\n","from midi_processor.processor import decode_midi, encode_midi\n","tf.executing_eagerly()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tOUtJ97jnJHx","colab":{}},"source":["l_r = None\n","batch_size = 2\n","pickle_dir = 'music'\n","max_seq = 2048\n","epochs = 5\n","is_reuse = False\n","load_path = None\n","save_path = datetime.datetime.now().strftime('%Y-%m-%d')\n","multi_gpu = True\n","num_layer = 6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S3vb_7QdngrW","colab":{}},"source":["dataset = Data('dataset/processed')\n","print(dataset)\n","learning_rate = callback.CustomSchedule(par.embedding_dim) if l_r is None else l_r\n","opt = Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","mt = MusicTransformerDecoder(\n","            embedding_dim=256,\n","            vocab_size=par.vocab_size,\n","            num_layer=num_layer,\n","            max_seq=max_seq,\n","            dropout=0.2,\n","            debug=False, loader_path=load_path)\n","mt.compile(optimizer=opt, loss=callback.transformer_dist_train_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DV-qQqe_TM3U"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ghmPk2DsTPv1","colab":{}},"source":["current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","train_log_dir = 'logs/mt_decoder/'+current_time+'/train'\n","eval_log_dir = 'logs/mt_decoder/'+current_time+'/eval'\n","train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n","eval_summary_writer = tf.summary.create_file_writer(eval_log_dir)\n","\n","idx = 0\n","for e in range(epochs):\n","    mt.reset_metrics()\n","    for b in range(len(dataset.files) // batch_size):\n","        try:\n","            batch_x, batch_y = dataset.slide_seq2seq_batch(batch_size, max_seq)\n","        except:\n","            continue\n","        result_metrics = mt.train_on_batch(batch_x, batch_y)\n","        if b % 100 == 0:\n","            eval_x, eval_y = dataset.slide_seq2seq_batch(batch_size, max_seq, 'eval')\n","            eval_result_metrics, weights = mt.evaluate(eval_x, eval_y)\n","            mt.save(save_path)\n","            with train_summary_writer.as_default():\n","                if b == 0:\n","                    tf.summary.histogram(\"target_analysis\", batch_y, step=e)\n","                    tf.summary.histogram(\"source_analysis\", batch_x, step=e)\n","\n","                tf.summary.scalar('loss', result_metrics[0], step=idx)\n","                tf.summary.scalar('accuracy', result_metrics[1], step=idx)\n","\n","            with eval_summary_writer.as_default():\n","                if b == 0:\n","                    mt.sanity_check(eval_x, eval_y, step=e)\n","\n","                tf.summary.scalar('loss', eval_result_metrics[0], step=idx)\n","                tf.summary.scalar('accuracy', eval_result_metrics[1], step=idx)\n","                for i, weight in enumerate(weights):\n","                    with tf.name_scope(\"layer_%d\" % i):\n","                        with tf.name_scope(\"w\"):\n","                            utils.attention_image_summary(weight, step=idx)\n","                # for i, weight in enumerate(weights):\n","                #     with tf.name_scope(\"layer_%d\" % i):\n","                #         with tf.name_scope(\"_w0\"):\n","                #             utils.attention_image_summary(weight[0])\n","                #         with tf.name_scope(\"_w1\"):\n","                #             utils.attention_image_summary(weight[1])\n","            idx += 1\n","            print('\\n====================================================')\n","            print('Epoch/Batch: {}/{}'.format(e, b))\n","            print('Train >>>> Loss: {:6.6}, Accuracy: {}'.format(result_metrics[0], result_metrics[1]))\n","            print('Eval >>>> Loss: {:6.6}, Accuracy: {}'.format(eval_result_metrics[0], eval_result_metrics[1]))\n","              \n","            "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WiGVwuo3nJH4"},"source":["# Generate Music"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AwKrL1_AnJH5","colab":{}},"source":["max_seq = 2048\n","load_path = save_path\n","mode = 'dec'\n","beam = None             # int type\n","length = 2048           # int type\n","current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","save_path = 'music/generated_'+current_time+'.mid'\n","gen_log_dir = 'logs/mt_decoder/generate_'+current_time+'/generate'\n","gen_summary_writer = tf.summary.create_file_writer(gen_log_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VWGsTXB8nJH7","colab":{}},"source":["\n","if mode == 'enc-dec':\n","    print(\">> generate with original seq2seq wise... beam size is {}\".format(beam))\n","    mt = MusicTransformer(\n","            embedding_dim=256,\n","            vocab_size=par.vocab_size,\n","            num_layer=6,\n","            max_seq=2048,\n","            dropout=0.2,\n","            debug=False, loader_path=load_path)\n","else:\n","    print(\">> generate with decoder wise... beam size is {}\".format(beam))\n","    mt = MusicTransformerDecoder(loader_path=load_path)\n","\n","inputs = encode_midi('dataset/midi/BENABD10.mid')\n","\n","\n","with gen_summary_writer.as_default():\n","    result = mt.generate(inputs[:10], beam=beam, length=length, tf_board=True)\n","\n","for i in result:\n","    print(i)\n","\n","if mode == 'enc-dec':\n","    decode_midi(list(inputs[-1*par.max_seq:]) + list(result[1:]), file_path=save_path)\n","else:\n","    decode_midi(result, file_path=save_path)\n"],"execution_count":0,"outputs":[]}]}